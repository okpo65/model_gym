folds: 1
params:
  encoder_hidden_list: [512, 256, 128]
  decoder_hidden_list: [128, 256, 512]
  bottleneck_size: 50
  emphasis: 0.8
  dropout_ratio: 0.3

optimizer:
  init_lr: 5e-5
  l2_reg: 2e-3

scheduler:
  gamma: 0.995
  patience: 30
  verbose: 0
  cooldown: 2
  min_lr: 1e-7

earlystopper:
  min_delta: 1e-7
  patience: 10
  verbose: 1

noise_ratio:
  num: 0.2
  cat: 0.25

batch_size: 512
iterations: 3000

eval_verbose: 1

loss_weight:
  cat: 0.2
  num: 1.0

path: res/models
name: dae_mlp
result: dae_mlp_1to7
