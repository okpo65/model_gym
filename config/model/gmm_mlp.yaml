folds: 1
params:
  hidden_size_list: [2048, 1024, 512, 256, 128, 64]
  dropout_ratio: 0.2
  num_components: 3


optimizer:
  init_lr: 5e-5
  l2_reg: 2e-3

scheduler:
  gamma: 0.995
  patience: 30
  verbose: 0
  cooldown: 2
  min_lr: 1e-7

earlystopper:
  min_delta: 1e-7
  patience: 10
  verbose: 1

batch_size: 512
iterations: 3000

eval_verbose: 1

path: res/models
name: gmm_mlp
result: gmm_mlp_test
