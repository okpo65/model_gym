folds: 1
params:
  hidden_size_list: [512, 256, 128]
  dropout_ratio: 0.2

optimizer:
  init_lr: 5e-5
  l2_reg: 2e-3

scheduler:
  gamma: 0.995
  patience: 30
  verbose: 0
  cooldown: 2
  min_lr: 1e-7

earlystopper:
  min_delta: 1e-7
  patience: 10
  verbose: 1

batch_size: 512
iterations: 3000

eval_verbose: 1

path: res/models
name: mlp
result: mlp_1to7_test
