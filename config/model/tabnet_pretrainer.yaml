folds: 1

params:
  n_d: 30
  n_a: 30
  n_steps: 3
  gamma: 1.3
  lambda_sparse: 1e-3
  optimizer_lr: 3e-5
  scheduler_step_size: 50
  scheduler_gamma: 0.9
  mask_type: entmax # sparsemax, entmax

fit_params:
  max_epochs: 1000
  patience: 30
#  batch_size: 1024
  batch_size: 1024 #4096
  virtual_batch_size: 256
  num_workers: 32
  drop_last: False

eval_metric: logloss # 'auc', 'accuracy', 'balanced_accuracy', 'logloss'

name: tabnet_pretrainer

path: res/models
result: tabnet_pretrainer_qt3000_32_1to2 #tabnet_qt3000_32_1to7_test
verbose: 500